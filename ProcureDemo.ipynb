{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/loren198/RCPSP_1/blob/master/ProcureDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OThnSQ9xCNdp",
        "outputId": "ee15dcd2-4174-4e53-b8e4-47ec71ccb9f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.16.0-py3-none-any.whl (266 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/266.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m256.0/266.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.9/266.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.16.0\n",
            "Collecting datetime\n",
            "  Downloading DateTime-5.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zope.interface (from datetime)\n",
            "  Downloading zope.interface-6.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.3/247.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from datetime) (2023.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.interface->datetime) (67.7.2)\n",
            "Installing collected packages: zope.interface, datetime\n",
            "Successfully installed datetime-5.5 zope.interface-6.2\n"
          ]
        }
      ],
      "source": [
        "%pip install openai --upgrade\n",
        "#%pip install dotenv\n",
        "%pip install datetime\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PYS3QUy0C-UA"
      },
      "outputs": [],
      "source": [
        "#import os,dotenv\n",
        "#from dotenv import load_dotenv\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ycWRf80WDtZI"
      },
      "outputs": [],
      "source": [
        "# For local key\n",
        "# Import Key and Base from .env\n",
        "# load_dotenv(\"secrets.env\")\n",
        "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "# openai.organization = os.getenv(\"OPENAI_ORGANIZATION\")\n",
        "\n",
        "# param for have result more deterministic ( 0) or creative (1) you could have step for experimentations like 0.5\n",
        "temperature = 0.2\n",
        "\n",
        "from google.colab import userdata\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "# openai.organization = userdata.get('OPENAI_ORGANIZATION')\n",
        "\n",
        "\n",
        "\n",
        "# Verify if loading is correct\n",
        "# print(\"OpenAI organization : \" + openai.organization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixSDg8yhXz9W"
      },
      "outputs": [],
      "source": [
        "#Import multiple files\n",
        "import glob\n",
        "folder_path = \"/content/Documentation\"\n",
        "\n",
        "# Use glob to get a list of files in the folder\n",
        "files = glob.glob(folder_path + '/*')\n",
        "\n",
        "# Create a list to store file IDs\n",
        "file_ids = []\n",
        "\n",
        "# Iterate through files in the folder and upload each file\n",
        "for file_path in files:\n",
        "    # Upload each file with \"assistants\" purpose\n",
        "    file = openai.files.create(\n",
        "        file=open(file_path, \"rb\"),\n",
        "        purpose='assistants'\n",
        "    )\n",
        "\n",
        "    # Append the file ID to the list\n",
        "    file_ids.append(file.id)\n",
        "\n",
        "    # Optionally print information about the uploaded file\n",
        "    print(f\"Uploaded file: {file_path}, ID: {file.id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHQi1fimycBb"
      },
      "outputs": [],
      "source": [
        "#create assistant\n",
        "assistant = openai.beta.assistants.create(\n",
        "  instructions=\"Select the best software option based only on the documents provided and user needs. The answer must be maximum 3 bullets, each with one software option, ordered by relevance. For each bullet, provide the software commercial name, price range and a 1-2 line reasoning for your selection\",\n",
        "  model=\"gpt-4-turbo-preview\",\n",
        "  tools=[{\"type\": \"retrieval\"}],\n",
        "  file_ids=file_ids\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ik2BJRfOkvAE"
      },
      "outputs": [],
      "source": [
        "#if already created, use this to update\n",
        "\n",
        "assistant = openai.beta.assistants.update(\n",
        "  assistant_id=\"asst_OnoUijWYrtcaOLCHPbgyBQ5M\",\n",
        "  instructions=\"Select the best software option based only on the documents provided and user needs. The answer must be maximum 2 bullets, each with one software option, ordered by relevance. For each bullet, provide the software commercial name, price range and a 1-2 line reasoning for your selection\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc2BSH_L9tog",
        "outputId": "d6287230-8f87-4add-f73f-895b42ff9797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are your needs?Non-sql relational database manager\n",
            "Based on the documents provided:\n",
            "\n",
            "1. **Amazon DynamoDB**\n",
            "   - **Price Range:** Pricing details not explicitly provided in the document, but it operates on a pay-as-you-go pricing model typical for AWS services.\n",
            "   - **Reasoning:** Amazon DynamoDB is a highly available and durable NoSQL database service that supports key-value and document data structures, offering flexibility in managing non-relational data with features like automatic scaling, ACID transactions, and global tables【11†source】.\n",
            "\n",
            "2. **Neo4j**\n",
            "   - **Price Range:** Pricing details not explicitly provided in the document, but it offers both a Community edition which is free and a paid Enterprise edition.\n",
            "   - **Reasoning:** Neo4j is a graph database management system known for its efficiency in handling highly connected data. The document covers detailed introduction to graph databases, the Cypher query language, data modelling, and data importing, emphasizing its capabilities in managing complex relationships and providing insights through graph visualizations【19†source】.\n",
            "Non-sql relational database manager\n"
          ]
        }
      ],
      "source": [
        "#Initialize thread\n",
        "\n",
        "thread = openai.beta.threads.create(\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": input(\"What are your needs?\"),\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "\n",
        "#run question\n",
        "run = openai.beta.threads.runs.create(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "#retrieve answer\n",
        "run = openai.beta.threads.runs.retrieve(\n",
        "  thread_id=thread.id,\n",
        "  run_id=run.id\n",
        ")\n",
        "\n",
        "import time\n",
        "\n",
        "while run.status !=\"completed\":\n",
        "  run = openai.beta.threads.runs.retrieve(\n",
        "  thread_id=thread.id,\n",
        "  run_id=run.id\n",
        ")\n",
        "  time.sleep (2)\n",
        "  #print(run.status)\n",
        "\n",
        "\n",
        "\n",
        "thread_messages = openai.beta.threads.messages.list(\n",
        "    thread_id=thread.id)\n",
        "#print(thread_messages.data[0])\n",
        "for message in thread_messages.data:\n",
        "    for content in message.content:\n",
        "            print(content.text.value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0YDw6lepqa7",
        "outputId": "534dcdba-386a-45e4-9981-be3ec68e7ba3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Assistant(id='asst_OnoUijWYrtcaOLCHPbgyBQ5M', created_at=1710565174, description=None, file_ids=['file-ZVCRJMjyaIRDaPUwK3zrs5RL', 'file-PMWYYvWidxbbAGDODbNfJ0QJ', 'file-U8wRajE4XAcQtdLBj33UzF7m'], instructions='You are a technical expert in a software specified by the user. The user will provide the name of the software and a document with multiple questions regarding that software. Answer all user questions in the following way: first, restate in exactly the same words the user first question. Then, in a new line provide your answer to the question and cite in what page you found it. Repeat the process for all questions in the document, numbering the questions.', metadata={}, model='gpt-4-turbo-preview', name=None, object='assistant', tools=[RetrievalTool(type='retrieval')])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "#update assistant to respond to questions\n",
        "openai.beta.assistants.update(\n",
        "  assistant_id=assistant.id,\n",
        "  instructions= \"You are a technical expert in a software specified by the user. The user will provide the name of the software and a document with multiple questions regarding that software. Answer all user questions in the following way: first, restate in exactly the same words the user first question. Then, in a new line provide your answer to the question and cite in what page you found it. Repeat the process for all questions in the document, numbering the questions.\",\n",
        "  #instructions= \"You are a technical expert in a software specified by the user. The user will provide the name of the software and a document with questions regarding that software. Based only on the documentation of that software that you have access to, answer the user questions in the following way: first, restate in exactly the same words the user first question. Then, in a new line provide your answer to the question and cite in what page you found it. Repeat the process for subsequent questions. If the answer is not available, just say Answer not available\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xphuQ4WPzZsh",
        "outputId": "147f9047-9293-42cc-8811-33acfe782bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What software are you looking for? Neo4J\n",
            "I'm unable to access the document directly due to its incompatibility with the browsing tool. Could you please upload the content of the document as text, or describe the questions you need assistance with? This will enable me to assist you more effectively.\n",
            "Neo4J. Answer the questions in the file attached.\n"
          ]
        }
      ],
      "source": [
        "# Upload a file with an \"assistants\" purpose\n",
        "file = openai.files.create(\n",
        "  file=open(\"/content/Neo4JSampleQ2.pdf\", \"rb\"),\n",
        "  purpose='assistants'\n",
        ")\n",
        "\n",
        "threadQ = openai.beta.threads.create()\n",
        "\n",
        "message = openai.beta.threads.messages.create(\n",
        "  thread_id=threadQ.id,\n",
        "  role=\"user\",\n",
        "  content=input(\"What software are you looking for? \") + \". Answer the questions in the file attached.\",\n",
        "  file_ids=[file.id]\n",
        ")\n",
        "\n",
        "#run question\n",
        "runQ = openai.beta.threads.runs.create(\n",
        "  thread_id=threadQ.id,\n",
        "  assistant_id=assistant.id\n",
        ")\n",
        "\n",
        "\n",
        "#retrieve answer\n",
        "runQ = openai.beta.threads.runs.retrieve(\n",
        "  thread_id=threadQ.id,\n",
        "  run_id=runQ.id\n",
        ")\n",
        "\n",
        "import time\n",
        "\n",
        "#time.sleep (90)\n",
        "while runQ.status !=\"completed\":\n",
        "  time.sleep (2)\n",
        "  runQ = openai.beta.threads.runs.retrieve(\n",
        "  thread_id=threadQ.id,\n",
        "  run_id=runQ.id\n",
        ")\n",
        "\n",
        "  #print(run.status)\n",
        "\n",
        "thread_messages = openai.beta.threads.messages.list(\n",
        "    thread_id=threadQ.id)\n",
        "#print(thread_messages.data[0])\n",
        "for message in thread_messages.data:\n",
        "    for content in message.content:\n",
        "            print(content.text.value)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message = openai.beta.threads.messages.create(\n",
        "  thread_id=threadQ.id,\n",
        "  role=\"user\",\n",
        "  content=\"Yes you can read the file. Retry\",\n",
        "  file_ids=[file.id]\n",
        ")\n",
        "\n",
        "#run question\n",
        "runQ = openai.beta.threads.runs.create(\n",
        "  thread_id=threadQ.id,\n",
        "  assistant_id=assistant.id\n",
        ")\n",
        "\n",
        "\n",
        "#retrieve answer\n",
        "runQ = openai.beta.threads.runs.retrieve(\n",
        "  thread_id=threadQ.id,\n",
        "  run_id=runQ.id\n",
        ")\n",
        "\n",
        "while runQ.status !=\"completed\":\n",
        "  time.sleep (2)\n",
        "  runQ = openai.beta.threads.runs.retrieve(\n",
        "  thread_id=threadQ.id,\n",
        "  run_id=runQ.id\n",
        ")\n",
        "  #print(run.status)\n",
        "\n",
        "\n",
        "thread_messages = openai.beta.threads.messages.list(\n",
        "    thread_id=threadQ.id)\n",
        "#print(thread_messages.data[0])\n",
        "for message in thread_messages.data:\n",
        "    for content in message.content:\n",
        "            print(content.text.value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vF4f5qpeiWt",
        "outputId": "e1b2b164-8aae-4425-e20c-44af2d1eb82a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. What are the Python integration options available?\n",
            "\n",
            "Neo4J can be integrated with Python using the Neo4j Python driver, which is officially supported by Neo4J. This driver allows for a direct connection to the database using Cypher, Neo4J's query language. Additionally, Py2neo, a third-party library, provides a more Pythonic way to work with Neo4J, including OGM (Object Graph Mapper) support for modeling and interacting with the database in a more object-oriented manner.\n",
            "\n",
            "2. Can you provide details about the performance benchmarks for typical use cases especially for large datasets and complex queries?\n",
            "\n",
            "Details about performance benchmarks for Neo4J, particularly for large datasets and complex queries, are usually found in the Neo4J whitepapers and performance analysis reports. These documents provide insights into various performance metrics like query execution time, read/write throughput, and scalability under different workloads. Performance can highly depend on factors such as the database schema design, indexes, the complexity of queries, and hardware specifications.\n",
            "\n",
            "3. Can you explain the theory behind graph databases used by Neo4J?\n",
            "\n",
            "The theory behind graph databases, including Neo4J, is based on graph theory from mathematics. Graph databases use nodes (to represent entities), relationships (to represent connections between entities), properties (key-value pairs associated with nodes and relationships), and labels (to group nodes and relationships) to model and store data. The emphasis is on the connections between data points, making them highly suitable for applications where relationships are a key aspect, such as social networks, recommendation engines, and network analysis. This approach contrasts with traditional relational databases that focus on storing data in tables and establishing relationships through foreign keys and joins, which can become inefficient for deeply connected data.\n",
            "\n",
            "4. Can Cypher be extended with own user defined functions?\n",
            "\n",
            "Yes, Neo4J allows Cypher, its query language, to be extended with user-defined functions (UDFs) and procedures. These are written in Java and deployed to the Neo4J server, where they can be invoked directly from Cypher queries. This feature enables users to implement custom logic and operations that are not natively supported by Cypher, thereby significantly enhancing the language's flexibility and capabilities for specific use cases.\n",
            "\n",
            "5. Are HTTP APIs available?\n",
            "\n",
            "Neo4J provides a comprehensive RESTful HTTP API that allows for interacting with the database over the web. This API facilitates executing Cypher queries, managing transactions, and accessing the database’s resources and administration tasks. It is especially useful for applications and services that require integrating Neo4J functionality over HTTP, enabling developers to leverage Neo4J's capabilities from a wide range of programming environments beyond those directly supported by official drivers.\n",
            "Yes you can read the file. Retry\n",
            "I'm sorry, but it seems like the file you're asking me to reference is not accessible with the tool I use to browse and extract information from documents. Could you perhaps re-upload the document or ensure it's in a compatible format for analysis?\n",
            "Neo4J. Answer the questions in the file attached.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOr0cxZqkHrCqT8o0bl0g4Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}